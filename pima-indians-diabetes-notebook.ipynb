{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/monicacruzsilva/pima-indians-diabetes-notebook?scriptVersionId=181504133\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T16:58:12.865757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analytics libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EAD)","metadata":{}},{"cell_type":"code","source":"# # Visualizando as primeiras linhas do DataFrame\nprint(\"Primeiras linhas do DataFrame:\")\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary statistics - numeric only\nprint(\"\\nSummary statistics of the dataset:\")\nprint(data.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* BloodPressure, Glucose, SkinThickness,Insulin, BMI  = 0 can be a outlier","metadata":{}},{"cell_type":"code","source":"# total de observações\ndata.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values and data types\ndatadict = pd.DataFrame(data.dtypes)\ndatadict.columns = [\"Dtype\"]\ndatadict['Valores_Nulos'] = data.isnull().sum()\ndatadict['%_Valores_Nulos'] = (data.isnull().sum() / data.shape[0]) * 100\ndatadict['NUnique']=data.nunique()\ndatadict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### seleciona variaveis numericas\nnum_data = data.select_dtypes(include=['float64', 'int64'])\n\n## calcula a matriz de correlação\ncorr = num_data.corr()\n\n# Plot\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr, annot=True, cmap='viridis', fmt=\".2f\", linewidths=0.5)\nplt.title('Matriz de Correlacao')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Histograma das variáveis numéricas\ndata.hist(figsize=(12, 10))\nplt.suptitle('Histogramas das Variáveis Numéricas')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Boxplot para variáveis numéricas em relação à variável alvo\nplt.figure(figsize=(12, 8))\n\n# Selecionando as variáveis numéricas\nnumeric_columns = data.select_dtypes(include=['int', 'float'])\n\nfor i, coluna in enumerate(numeric_columns):\n    plt.subplot(3, 3, i + 1)\n    sns.boxplot(x=data['Outcome'], y=data[coluna])\n    plt.title(coluna)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fitting Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n# Separando os dados em features (X) e target (y)\nX = data.drop('Outcome', axis=1)\ny = data['Outcome']\n\n# Dividindo os dados em conjunto de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inicializando e ajustando o modelo de regressão logística\nmodelo = LogisticRegression(solver='lbfgs', max_iter=200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelo.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fazendo previsões no conjunto de teste\ny_predict = modelo.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy Score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Calculando a precisão do modelo\nprecisao = accuracy_score(y_test, previsoes)\nprint(\"Precisão do modelo de regressão logística:\", precisao)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Calculando a matriz de confusão\nmatriz_confusao = confusion_matrix(y_test, previsoes)\n\n# Plotando a matriz de confusão\nplt.figure(figsize=(8, 6))\nsns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\nplt.xlabel('Previsão')\nplt.ylabel('Valor Real')\nplt.title('Matriz de Confusão')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Metrics**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Avaliando o modelo\nrelatorio_classificacao = classification_report(y_test, previsoes)\nprint(\"Relatório de Classificação:\\n\", relatorio_classificacao)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}